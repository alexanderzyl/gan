from typing import Tuple

import numpy as np
from keras import Model, Sequential
from keras.src.initializers.initializers import RandomNormal
from keras.src.layers import Conv2D, LeakyReLU, Dropout, Flatten, Dense, Reshape, Conv2DTranspose, BatchNormalization
from keras.src.optimizers.adam import Adam

from dcgan.generic import DcGan


class MnistGan(DcGan):
    def __init__(self, latent_dim: int = 100):
        super().__init__(latent_dim)
        self.tensorboard_gan = None
        self.file_writer = None

    # Generate real samples for training
    def generate_real_samples(self, dataset, n_samples):
        ix = np.random.randint(0, dataset.shape[0], n_samples)
        X = dataset[ix]
        y = np.ones((n_samples, 1))
        return X, y

    # Generate latent points for generator
    def generate_latent_points(self, latent_dim, n_samples):
        return np.random.randn(latent_dim * n_samples).reshape(n_samples, latent_dim)

    # Generate fake samples generated by the generator
    def generate_fake_samples(self, n_samples: int) -> Tuple[np.array, np.array]:
        latent_points = self.generate_latent_points(self.latent_dim, n_samples)
        X = self.generator.predict(latent_points)
        y = np.zeros((n_samples, 1))
        return X, y

    # Define the Discriminator model
    def create_discriminator(self, in_shape=(28, 28, 1)) -> Model:
        model = Sequential()
        model.add(Conv2D(64, (3, 3), strides=(2, 2), padding='same', input_shape=in_shape))
        model.add(LeakyReLU(alpha=0.2))
        model.add(Dropout(0.4))
        model.add(Conv2D(64, (3, 3), strides=(2, 2), padding='same'))
        model.add(LeakyReLU(alpha=0.2))
        model.add(Dropout(0.4))
        model.add(Flatten())
        model.add(Dense(1, activation='sigmoid'))
        opt = Adam(learning_rate=0.0002, beta_1=0.5)
        model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])
        return model

    # Define the Generator model
    def create_generator(self) -> Model:
        model = Sequential()
        n_nodes = 128 * 7 * 7
        init = RandomNormal(stddev=0.02)
        model.add(Dense(n_nodes, input_dim=self.latent_dim, kernel_initializer=init))
        model.add(LeakyReLU(alpha=0.2))
        model.add(Reshape((7, 7, 128)))
        model.add(Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'))
        model.add(BatchNormalization())
        model.add(LeakyReLU(alpha=0.2))
        model.add(Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'))
        model.add(BatchNormalization())
        model.add(LeakyReLU(alpha=0.2))
        # use tanh
        model.add(Conv2D(1, (7, 7), activation='tanh', padding='same'))
        return model